{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ru2lJ4XSUJ5_",
        "outputId": "f2aa27ce-99c3-4a47-9b5d-1ba1de5125a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rHit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "\u001b[33m\r0% [Connecting to archive.ubuntu.com (185.125.190.81)] [Connecting to security.\u001b[0m\r                                                                               \rHit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:3 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:4 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "53 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "\u001b[1;33mW: \u001b[0mSkipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\u001b[0m\n",
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.5.3)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.10/dist-packages (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "#Cargar\n",
        "\n",
        "!sudo apt update\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "#Check this site for the latest download link https://www.apache.org/dyn/closer.lua/spark/spark-3.2.1/spark-3.2.1-bin-hadoop3.2.tgz\n",
        "!wget -q https://archive.apache.org/dist/spark/spark-3.2.1/spark-3.2.1-bin-hadoop3.2.tgz\n",
        "!tar xf spark-3.2.1-bin-hadoop3.2.tgz\n",
        "!pip install -q findspark\n",
        "!pip install pyspark\n",
        "!pip install py4j\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear una sesi√≥n de Spark\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Movie_PIA\") \\\n",
        "    .getOrCreate()"
      ],
      "metadata": {
        "id": "Vr-JwYipUbhY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "outputId": "1f27a6d1-92fd-4829-a066-4751f47ee406"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ConnectionRefusedError",
          "evalue": "[Errno 111] Connection refused",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-455caf80a0e3>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mspark\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0mappName\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Movie_PIA\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;34m.\u001b[0m\u001b[0mgetOrCreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/sql/session.py\u001b[0m in \u001b[0;36mgetOrCreate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    491\u001b[0m                 \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_instantiatedSession\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msession\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m                     \u001b[0msparkConf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkConf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m                         \u001b[0msparkConf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/conf.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, loadDefaults, _jvm, _jconf)\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0m_jvm\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m                 \u001b[0;31m# JVM is created, so create self._jconf directly through JVM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jconf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparkConf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloadDefaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1710\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mUserHelpAutoCompletion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1712\u001b[0;31m         answer = self._gateway_client.send_command(\n\u001b[0m\u001b[1;32m   1713\u001b[0m             \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mREFLECTION_COMMAND_NAME\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1714\u001b[0m             \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mREFL_GET_UNKNOWN_SUB_COMMAND_NAME\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_id\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1034\u001b[0m          \u001b[0;32mif\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1035\u001b[0m         \"\"\"\n\u001b[0;32m-> 1036\u001b[0;31m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1037\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/py4j/clientserver.py\u001b[0m in \u001b[0;36m_get_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mconnection\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msocket\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m             \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_new_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/py4j/clientserver.py\u001b[0m in \u001b[0;36m_create_new_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    289\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_parameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython_parameters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m             self.gateway_property, self)\n\u001b[0;32m--> 291\u001b[0;31m         \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect_to_java_server\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    292\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_thread_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/py4j/clientserver.py\u001b[0m in \u001b[0;36mconnect_to_java_server\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    436\u001b[0m                 self.socket = self.ssl_context.wrap_socket(\n\u001b[1;32m    437\u001b[0m                     self.socket, server_hostname=self.java_address)\n\u001b[0;32m--> 438\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_address\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_port\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakefile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_connected\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mConnectionRefusedError\u001b[0m: [Errno 111] Connection refused"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TJ-UAuj0GBPk",
        "outputId": "638d7525-de36-4e95-8f46-2923969cbd9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# cargar el archivo limpio que ya est√° en mi drive\n",
        "\n",
        "file_path = '/content/drive/My Drive/movies_clean_final.csv'\n",
        "df = spark.read.csv(file_path, header=True, inferSchema=True)"
      ],
      "metadata": {
        "id": "sSeUZi5QGX4k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Revisar que columnas tienen nulos\n",
        "from pyspark.sql.functions import col, when, sum\n",
        "\n",
        "null_counts = df.select([sum(col(c).isNull().cast(\"int\")).alias(c) for c in df.columns])\n",
        "\n",
        "null_counts.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xUiw9We9Gz7U",
        "outputId": "a14dd90a-177e-4a86-d67e-d97e2a35b9df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+-----+------------+----------+------+------------+-------+-----+------+-----------------+--------------+--------+----------+------+--------------------+--------------------+----------------+------------+\n",
            "|movie_id|title|vote_average|vote_count|status|release_date|revenue|adult|budget|original_language|original_title|overview|popularity|genres|production_companies|production_countries|spoken_languages|year_release|\n",
            "+--------+-----+------------+----------+------+------------+-------+-----+------+-----------------+--------------+--------+----------+------+--------------------+--------------------+----------------+------------+\n",
            "|       0|    0|           0|         0|     0|           0|      0|    0|     0|                0|             0|     217|         5|     5|                   5|                   5|               5|           5|\n",
            "+--------+-----+------------+----------+------+------------+-------+-----+------+-----------------+--------------+--------+----------+------+--------------------+--------------------+----------------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Limpieza\n",
        "df = df.dropna()"
      ],
      "metadata": {
        "id": "mslEXeKdAJve"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l6SVJ-IX-I1J",
        "outputId": "bafc5f82-cc91-476a-ec01-9f5a6ddfef9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- movie_id: integer (nullable = true)\n",
            " |-- title: string (nullable = true)\n",
            " |-- vote_average: double (nullable = true)\n",
            " |-- vote_count: integer (nullable = true)\n",
            " |-- status: string (nullable = true)\n",
            " |-- release_date: string (nullable = true)\n",
            " |-- revenue: long (nullable = true)\n",
            " |-- adult: boolean (nullable = true)\n",
            " |-- budget: integer (nullable = true)\n",
            " |-- original_language: string (nullable = true)\n",
            " |-- original_title: string (nullable = true)\n",
            " |-- overview: string (nullable = true)\n",
            " |-- popularity: double (nullable = true)\n",
            " |-- genres: string (nullable = true)\n",
            " |-- production_companies: string (nullable = true)\n",
            " |-- production_countries: string (nullable = true)\n",
            " |-- spoken_languages: string (nullable = true)\n",
            " |-- year_release: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afTsTszF_cc6",
        "outputId": "1c4a9801-d39b-4ed2-fdd2-801900c99920"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+---------------+------------+----------+--------+------------+----------+-----+---------+-----------------+---------------+--------------------+----------+--------------------+--------------------+--------------------+--------------------+------------+\n",
            "|movie_id|          title|vote_average|vote_count|  status|release_date|   revenue|adult|   budget|original_language| original_title|            overview|popularity|              genres|production_companies|production_countries|    spoken_languages|year_release|\n",
            "+--------+---------------+------------+----------+--------+------------+----------+-----+---------+-----------------+---------------+--------------------+----------+--------------------+--------------------+--------------------+--------------------+------------+\n",
            "| 4520010|      Inception|       8.364|     34495|Released|   7/15/2010| 825532764|false|160000000|               en|      Inception|\\Cobb a skilled t...|    83.952|Action Science Fi...|Legendary Picture...|United Kingdom Un...|English French Ja...|        2010|\n",
            "| 4520011|   Interstellar|       8.417|     32571|Released|  11/05/2014| 701729206|false|165000000|               en|   Interstellar|The adventures of...|   140.241|Adventure Drama S...|Legendary Picture...|United Kingdom Un...|             English|        2014|\n",
            "| 4520012|The Dark Knight|       8.512|     30619|Released|   7/16/2008|1004558444|false|185000000|               en|The Dark Knight|Batman raises the...|   130.643|Drama Action Crim...|DC Comics Legenda...|United Kingdom Un...|    English Mandarin|        2008|\n",
            "| 4520013|         Avatar|       7.573|     29815|Released|  12/15/2009|2923706026|false|237000000|               en|         Avatar|In the 22nd centu...|    79.932|Action Adventure ...|Dune Entertainmen...|United States of ...|     English Spanish|        2009|\n",
            "| 4520014|   The Avengers|        7.71|     29166|Released|   4/25/2012|1518815515|false|220000000|               en|   The Avengers|When an unexpecte...|    98.082|Science Fiction A...|      Marvel Studios|United States of ...|English Hindi Rus...|        2012|\n",
            "+--------+---------------+------------+----------+--------+------------+----------+-----+---------+-----------------+---------------+--------------------+----------+--------------------+--------------------+--------------------+--------------------+------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pzUlMkAJ_caJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "N8I3QfyV_cXZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NurWo1jf_cUb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5bmFJbUz_cMS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xU4hQAta_beB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col, when\n",
        "\n",
        "#Crear una columna de \"mas votadas\" con valor de 1 y cero el resto\n",
        "df1 = df.withColumn(\"high_rating\", when(col(\"vote_average\") >= 7.0, 1).otherwise(0))\n",
        "\n",
        "#seleccionar columnas para el modelo\n",
        "features = [\"budget\", \"popularity\", \"revenue\", \"vote_count\", \"high_rating\"]\n",
        "\n",
        "#filtrar el df\n",
        "df1 = df1.select(features)\n",
        "\n",
        "#Quitar valores nulos\n",
        "df1 = df1.dropna()"
      ],
      "metadata": {
        "id": "DMIhwDuFWHYM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dividir el dataset entre conjunto de entrenamiento y prueba\n",
        "\n",
        "train_data1, test_data1 = df1.randomSplit([0.8, 0.2], seed=42)\n"
      ],
      "metadata": {
        "id": "dxB-aSMkXAd8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Regresi√≥n log√≠stica para estimar si una pelicula ser√° \"altamente votada\" o no"
      ],
      "metadata": {
        "id": "I6pfngFGMykB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import LogisticRegression\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "\n",
        "# Crear el vector de caracter√≠sticas\n",
        "assembler = VectorAssembler(inputCols=['budget', 'popularity', 'revenue', 'vote_count'], outputCol='features')\n",
        "train_data1 = assembler.transform(train_data1)\n",
        "\n",
        "# Crear el modelo\n",
        "lr = LogisticRegression(featuresCol='features', labelCol='high_rating')\n",
        "\n",
        "# Entrenar el modelo\n",
        "model1 = lr.fit(train_data1)"
      ],
      "metadata": {
        "id": "6HTPJlMYXPAB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preparar los datos de prueba\n",
        "test_data1 = assembler.transform(test_data1)\n",
        "\n",
        "# Hacer predicciones\n",
        "predictions = model1.transform(test_data1)\n",
        "\n",
        "# Mostrar resultados\n",
        "predictions.select(\"high_rating\", \"prediction\").show(10)\n",
        "\n",
        "# Evaluaci√≥n\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "\n",
        "evaluator = BinaryClassificationEvaluator(labelCol=\"high_rating\", rawPredictionCol=\"prediction\")\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "print(f\"Precisi√≥n del modelo: {accuracy:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LoRF8RxKXssZ",
        "outputId": "8b87eac8-eaff-491a-e364-0ff85dc6b007"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+----------+\n",
            "|high_rating|prediction|\n",
            "+-----------+----------+\n",
            "|          1|       0.0|\n",
            "|          1|       0.0|\n",
            "|          0|       0.0|\n",
            "|          0|       0.0|\n",
            "|          0|       0.0|\n",
            "|          0|       0.0|\n",
            "|          0|       0.0|\n",
            "|          0|       0.0|\n",
            "|          0|       0.0|\n",
            "|          0|       0.0|\n",
            "+-----------+----------+\n",
            "only showing top 10 rows\n",
            "\n",
            "Precisi√≥n del modelo: 0.51\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model1.save(\"logistic_regression_model\")"
      ],
      "metadata": {
        "id": "lUOcxprpYUp5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "import numpy as np\n",
        "\n",
        "# Extraer los coeficientes y el intercepto\n",
        "coef = np.array(model1.coefficients)\n",
        "intercept = np.array(model1.intercept)\n",
        "\n",
        "# Guardar coeficientes y el intercepto utilizando joblib\n",
        "joblib.dump((coef, intercept), \"logistic_regression_coefficients.pkl\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OMUnDDgIYfw4",
        "outputId": "d24cba5a-8063-4240-e334-da427fd7b835"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['logistic_regression_coefficients.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Segundo modelo\n",
        "\n"
      ],
      "metadata": {
        "id": "e3ILXP3jNRn7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql import functions as F\n",
        "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
        "from pyspark.ml import Pipeline"
      ],
      "metadata": {
        "id": "IY9CENFRTFEY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = df.select(\"movie_id\", \"title\", \"budget\", \"popularity\", \"revenue\", \"vote_average\", \"vote_count\")\n",
        "# Seleccionar y procesar columnas num√©ricas\n",
        "numeric_columns = [\"vote_average\", \"vote_count\", \"revenue\", \"budget\", \"popularity\"]\n",
        "\n",
        "# Crear un vector de caracter√≠sticas y escalarlo\n",
        "assembler = VectorAssembler(inputCols=numeric_columns, outputCol=\"features\")\n",
        "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaled_features\")\n",
        "\n",
        "# Pipeline para preprocesamiento\n",
        "pipeline = Pipeline(stages=[assembler, scaler])\n",
        "df_preprocessed = pipeline.fit(df2).transform(df2)\n",
        "\n",
        "# Mostrar datos preprocesados\n",
        "df_preprocessed.select(\"movie_id\", \"title\", \"scaled_features\").show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4g_cjHcXTYJR",
        "outputId": "70f609c0-dd06-48d6-bacf-759c9e1edf8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+-------------------------------------------------+-----------------------------------------------------------------------------------------------+\n",
            "|movie_id|title                                            |scaled_features                                                                                |\n",
            "+--------+-------------------------------------------------+-----------------------------------------------------------------------------------------------+\n",
            "|4520010 |Inception                                        |[2.6631819085474744,52.521391172026746,24.82587604873595,17.543447948063786,5.532013478671557] |\n",
            "|4520011 |Interstellar                                     |[2.6800576427838463,49.59194758266656,21.10278725162009,18.09168069644078,9.241174745835453]   |\n",
            "|4520012 |The Dark Knight                                  |[2.7103066003773435,46.619871758118194,30.20963491941436,20.284611689948754,8.608714942992284] |\n",
            "|4520013 |Avatar                                           |[2.4113195353216192,45.39571757628577,87.92329822589375,25.986232273069483,5.267115749204009]  |\n",
            "|4520014 |The Avengers                                     |[2.4549417162722413,44.407563267816556,45.67465685261046,24.122240928587708,6.4631092292627175]|\n",
            "|4520015 |Deadpool                                         |[2.4218270679593603,43.993421554559816,23.549814594354636,6.3594998811731225,4.792869739508001]|\n",
            "|4520016 |Avengers: Infinity War                           |[2.6284752098349355,42.195254777514926,61.72135568779867,32.8939649026196,10.170227752741663]  |\n",
            "|4520017 |Fight Club                                       |[2.686744254462409,41.472029359143775,3.0329296185606407,6.907732629550116,4.579567761824803]  |\n",
            "|4520018 |Guardians of the Galaxy                          |[2.5173500919388245,40.55848146225391,23.239363622597057,18.639913444817772,2.191336814289387] |\n",
            "|4520019 |Pulp Fiction                                     |[2.7026647584589862,39.42415949028232,6.432518633293904,0.9319956722408886,4.933028314278517]  |\n",
            "|4520020 |Forrest Gump                                     |[2.699162247579739,38.68723085345783,20.370776555093034,6.030560232146927,6.108001302869528]   |\n",
            "|4520021 |Harry Potter and the Philosophers Stone          |[2.52053419273814,38.64155345861333,29.365110660733585,13.705818709424834,12.22232852166664]   |\n",
            "|4520022 |Iron Man                                         |[2.4326530106770328,37.87265064539769,17.59768156492877,15.350516954555813,4.803544722635798]  |\n",
            "|4520023 |Django Unchained                                 |[2.601728763120685,37.565089520111435,12.791907980114054,10.964654967539866,3.573088179763275] |\n",
            "|4520024 |The Shawshank Redemption                         |[2.7708045155643375,37.53007018406399,0.852300268524645,2.7411637418849666,8.07938074876024]   |\n",
            "|4520025 |Avengers: Endgame                                |[2.6310224904743875,36.324186960169364,84.20314246481034,39.03417168444193,6.046257727618013]  |\n",
            "|4520026 |The Matrix                                       |[2.612873115918289,36.26023860738707,13.939150084166092,6.907732629550116,5.176971447235946]   |\n",
            "|4520027 |Titanic                                          |[2.5154396314592358,35.989219397976406,68.0891375618283,21.929309935079733,6.744217118294698]  |\n",
            "|4520028 |Joker                                            |[2.6007735328808903,35.66643247440866,32.311701354193346,6.030560232146927,3.592724877121815]  |\n",
            "|4520029 |The Lord of the Rings: The Fellowship of the Ring|[2.675281491584873,35.511129331937376,26.20426946186454,10.197129119812077,5.735299422802749]  |\n",
            "+--------+-------------------------------------------------+-----------------------------------------------------------------------------------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.linalg import DenseVector\n",
        "\n",
        "def compare_movies(movie_id_1, movie_id_2):\n",
        "    # Seleccionar las pel√≠culas\n",
        "    movie_1 = df_preprocessed.filter(F.col(\"movie_id\") == movie_id_1).select(\"title\", \"scaled_features\").first()\n",
        "    movie_2 = df_preprocessed.filter(F.col(\"movie_id\") == movie_id_2).select(\"title\", \"scaled_features\").first()\n",
        "\n",
        "    if not movie_1 or not movie_2:\n",
        "        raise ValueError(\"Uno o ambos movie_id no existen en el conjunto de datos.\")\n",
        "\n",
        "    # Extraer atributos escalados\n",
        "    title_1, features_1 = movie_1[\"title\"], movie_1[\"scaled_features\"]\n",
        "    title_2, features_2 = movie_2[\"title\"], movie_2[\"scaled_features\"]\n",
        "\n",
        "    # Calcular las diferencias entre los atributos\n",
        "    differences = [abs(f1 - f2) for f1, f2 in zip(features_1, features_2)]\n",
        "    comparison = {\n",
        "        \"movie_1\": title_1,\n",
        "        \"movie_2\": title_2,\n",
        "        \"differences\": differences,\n",
        "        \"attributes\": numeric_columns\n",
        "    }\n",
        "    return comparison\n",
        "\n",
        "# Ejemplo de comparaci√≥n\n",
        "comparison_result = compare_movies(4520010, 4520011)\n",
        "print(comparison_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pHj0AVwjT68A",
        "outputId": "66529bf3-4c4b-43f2-902a-2d01cd596f91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'movie_1': 'Inception', 'movie_2': 'Interstellar', 'differences': [0.016875734236371898, 2.929443589360183, 3.72308879711586, 0.5482327483769929, 3.7091612671638963], 'attributes': ['vote_average', 'vote_count', 'revenue', 'budget', 'popularity']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "from typing import Dict\n",
        "\n",
        "class MovieComparisonModel:\n",
        "    def __init__(self, df_preprocessed, numeric_columns):\n",
        "        \"\"\"\n",
        "        Inicializa el modelo de comparaci√≥n de pel√≠culas.\n",
        "\n",
        "        Args:\n",
        "            df_preprocessed: DataFrame de PySpark preprocesado con columnas escaladas.\n",
        "            numeric_columns: Lista de nombres de columnas num√©ricas para la comparaci√≥n.\n",
        "        \"\"\"\n",
        "        self.df_preprocessed = df_preprocessed\n",
        "        self.numeric_columns = numeric_columns\n",
        "\n",
        "    def find_movie_by_title(self, title: str) -> Dict:\n",
        "        \"\"\"\n",
        "        Busca una pel√≠cula por su t√≠tulo.\n",
        "\n",
        "        Args:\n",
        "            title: T√≠tulo de la pel√≠cula.\n",
        "\n",
        "        Returns:\n",
        "            Diccionario con el ID y los atributos de la pel√≠cula.\n",
        "        \"\"\"\n",
        "        movie = self.df_preprocessed.filter(F.col(\"title\") == title).first()\n",
        "        if not movie:\n",
        "            raise ValueError(f\"Pel√≠cula con t√≠tulo '{title}' no encontrada.\")\n",
        "        return {\"movie_id\": movie[\"movie_id\"], \"title\": movie[\"title\"], \"scaled_features\": movie[\"scaled_features\"]}\n",
        "\n",
        "    def compare_movies_by_title(self, title_1: str, title_2: str) -> Dict:\n",
        "        \"\"\"\n",
        "        Compara dos pel√≠culas por su t√≠tulo.\n",
        "\n",
        "        Args:\n",
        "            title_1: T√≠tulo de la primera pel√≠cula.\n",
        "            title_2: T√≠tulo de la segunda pel√≠cula.\n",
        "\n",
        "        Returns:\n",
        "            Diccionario con la comparaci√≥n de atributos.\n",
        "        \"\"\"\n",
        "        movie_1 = self.find_movie_by_title(title_1)\n",
        "        movie_2 = self.find_movie_by_title(title_2)\n",
        "\n",
        "        differences = [\n",
        "            abs(f1 - f2) for f1, f2 in zip(movie_1[\"scaled_features\"], movie_2[\"scaled_features\"])\n",
        "        ]\n",
        "\n",
        "        return {\n",
        "            \"movie_1\": movie_1[\"title\"],\n",
        "            \"movie_2\": movie_2[\"title\"],\n",
        "            \"differences\": differences,\n",
        "            \"attributes\": self.numeric_columns,\n",
        "        }"
      ],
      "metadata": {
        "id": "Bw7BKOmWUF2g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "import numpy as np\n",
        "from pyspark.sql import functions as F\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.sql import SparkSession\n",
        "import pickle\n",
        "\n",
        "df2 = df.select(\"movie_id\", \"title\", \"budget\", \"popularity\", \"revenue\", \"vote_average\", \"vote_count\")\n",
        "\n",
        "# Selecci√≥n de columnas para el modelo\n",
        "numeric_columns = [\"budget\", \"revenue\", \"vote_average\", \"vote_count\", \"popularity\"]\n",
        "\n",
        "# Usar VectorAssembler para combinar las columnas num√©ricas en un solo vector\n",
        "assembler = VectorAssembler(inputCols=numeric_columns, outputCol=\"features\")\n",
        "df2 = assembler.transform(df2)\n",
        "\n",
        "# Escalar los valores de las caracter√≠sticas usando MinMaxScaler (opcional pero √∫til para la comparaci√≥n)\n",
        "from pyspark.ml.feature import MinMaxScaler\n",
        "scaler = MinMaxScaler(inputCol=\"features\", outputCol=\"scaled_features\")\n",
        "scaler_model = scaler.fit(df2)\n",
        "df_scaled = scaler_model.transform(df2)\n",
        "\n",
        "# Extraer los coeficientes (caracter√≠sticas escaladas) para compararlas\n",
        "df_scaled = df_scaled.select(\"movie_id\", \"title\", \"scaled_features\")\n",
        "movies = df_scaled.collect()\n",
        "\n",
        "# Crear un diccionario con los coeficientes\n",
        "coef_dict = {}\n",
        "for movie in movies:\n",
        "    coef_dict[movie[\"title\"]] = np.array(movie[\"scaled_features\"])\n",
        "\n",
        "# Guardar los coeficientes en un archivo .pkl\n",
        "with open(\"movie_comparison_coefficients.pkl\", \"wb\") as f:\n",
        "    joblib.dump(coef_dict, f)\n",
        "\n",
        "print(\"Modelo guardado como 'movie_comparison_coefficients.pkl'.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HlVQHfi_W0lY",
        "outputId": "8318ecad-ad5f-4dd1-95fc-c5840292e9fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modelo guardado como 'movie_comparison_coefficients.pkl'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col, max\n",
        "\n",
        "\n",
        "df3 = df\n",
        "\n",
        "df3.show(5)\n",
        "df3.printSchema()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tg0TvtFP1Tfc",
        "outputId": "e9bda37a-0ae6-4741-af97-47fd65702c92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+---------------+------------+----------+--------+------------+----------+-----+---------+-----------------+---------------+--------------------+----------+--------------------+--------------------+--------------------+--------------------+------------+\n",
            "|movie_id|          title|vote_average|vote_count|  status|release_date|   revenue|adult|   budget|original_language| original_title|            overview|popularity|              genres|production_companies|production_countries|    spoken_languages|year_release|\n",
            "+--------+---------------+------------+----------+--------+------------+----------+-----+---------+-----------------+---------------+--------------------+----------+--------------------+--------------------+--------------------+--------------------+------------+\n",
            "| 4520010|      Inception|       8.364|     34495|Released|   7/15/2010| 825532764|false|160000000|               en|      Inception|\\Cobb a skilled t...|    83.952|Action Science Fi...|Legendary Picture...|United Kingdom Un...|English French Ja...|        2010|\n",
            "| 4520011|   Interstellar|       8.417|     32571|Released|  11/05/2014| 701729206|false|165000000|               en|   Interstellar|The adventures of...|   140.241|Adventure Drama S...|Legendary Picture...|United Kingdom Un...|             English|        2014|\n",
            "| 4520012|The Dark Knight|       8.512|     30619|Released|   7/16/2008|1004558444|false|185000000|               en|The Dark Knight|Batman raises the...|   130.643|Drama Action Crim...|DC Comics Legenda...|United Kingdom Un...|    English Mandarin|        2008|\n",
            "| 4520013|         Avatar|       7.573|     29815|Released|  12/15/2009|2923706026|false|237000000|               en|         Avatar|In the 22nd centu...|    79.932|Action Adventure ...|Dune Entertainmen...|United States of ...|     English Spanish|        2009|\n",
            "| 4520014|   The Avengers|        7.71|     29166|Released|   4/25/2012|1518815515|false|220000000|               en|   The Avengers|When an unexpecte...|    98.082|Science Fiction A...|      Marvel Studios|United States of ...|English Hindi Rus...|        2012|\n",
            "+--------+---------------+------------+----------+--------+------------+----------+-----+---------+-----------------+---------------+--------------------+----------+--------------------+--------------------+--------------------+--------------------+------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "root\n",
            " |-- movie_id: integer (nullable = true)\n",
            " |-- title: string (nullable = true)\n",
            " |-- vote_average: double (nullable = true)\n",
            " |-- vote_count: integer (nullable = true)\n",
            " |-- status: string (nullable = true)\n",
            " |-- release_date: string (nullable = true)\n",
            " |-- revenue: long (nullable = true)\n",
            " |-- adult: boolean (nullable = true)\n",
            " |-- budget: integer (nullable = true)\n",
            " |-- original_language: string (nullable = true)\n",
            " |-- original_title: string (nullable = true)\n",
            " |-- overview: string (nullable = true)\n",
            " |-- popularity: double (nullable = true)\n",
            " |-- genres: string (nullable = true)\n",
            " |-- production_companies: string (nullable = true)\n",
            " |-- production_countries: string (nullable = true)\n",
            " |-- spoken_languages: string (nullable = true)\n",
            " |-- year_release: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Paso 1: Obtener la pel√≠cula con mayor budget por a√±o\n",
        "max_budget = df3.groupBy(\"year_release\").agg(max(\"budget\").alias(\"max_budget\"))\n",
        "merged_budget = df3.join(max_budget, (df3.year_release == max_budget.year_release) & (df3.budget == max_budget.max_budget), \"inner\") \\\n",
        "                   .select(df3[\"*\"], max_budget[\"max_budget\"])  # Selecciona columnas de df y max_budget\n",
        "\n",
        "# Paso 2: Obtener la pel√≠cula con mayor revenue por a√±o\n",
        "max_revenue = df3.groupBy(\"year_release\").agg(max(\"revenue\").alias(\"max_revenue\"))\n",
        "merged_revenue = merged_budget.join(max_revenue, (merged_budget.year_release == max_revenue.year_release) & (merged_budget.revenue == max_revenue.max_revenue), \"inner\") \\\n",
        "                               .select(merged_budget[\"*\"], max_revenue[\"max_revenue\"])  # Selecciona columnas de merged_budget y max_revenue\n",
        "\n",
        "# Paso 3: Obtener la pel√≠cula con mayor vote_average por a√±o\n",
        "max_vote_average = df3.groupBy(\"year_release\").agg(max(\"vote_average\").alias(\"max_vote_average\"))\n",
        "final_result = merged_revenue.join(max_vote_average, (merged_revenue.year_release == max_vote_average.year_release) & (merged_revenue.vote_average == max_vote_average.max_vote_average), \"inner\") \\\n",
        "                              .select(merged_revenue[\"*\"], max_vote_average[\"max_vote_average\"])  # Selecciona columnas de merged_revenue y max_vote_average\n",
        "\n",
        "# Seleccionar solo las columnas necesarias para el resultado final\n",
        "final_output = final_result.select(\n",
        "    \"year_release\",\n",
        "    \"title\",\n",
        "    \"budget\",\n",
        "    \"revenue\",\n",
        "    \"vote_average\"\n",
        ")"
      ],
      "metadata": {
        "id": "_AKbKMctmmqG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import HashingTF, IDF\n",
        "from pyspark.ml.linalg import DenseVector\n",
        "from pyspark.sql.functions import col, udf\n",
        "from transformers import pipeline\n",
        "from pyspark.sql.functions import udf, col\n",
        "from pyspark.sql.types import StringType\n",
        "from textblob import TextBlob\n",
        "\n",
        "# Crear una sesi√≥n de Spark\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Movie_PIA\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# cargar el archivo limpio que ya est√° en mi drive\n",
        "\n",
        "file_path = '/content/drive/My Drive/movies_clean_final.csv'\n",
        "df = spark.read.csv(file_path, header=True, inferSchema=True)\n",
        "\n",
        "# Definir una funci√≥n para calcular el sentimiento\n",
        "def analyze_sentiment(text):\n",
        "    if text is None or text.strip() == \"\":\n",
        "        return \"Neutral\"\n",
        "    polarity = TextBlob(text).sentiment.polarity\n",
        "    if polarity > 0:\n",
        "        return \"Positivo\"\n",
        "    elif polarity < 0:\n",
        "        return \"Negativo\"\n",
        "    else:\n",
        "        return \"Neutral\"\n",
        "\n",
        "# Registrar la funci√≥n como UDF\n",
        "sentiment_udf = udf(analyze_sentiment, StringType())\n",
        "\n",
        "# Aplicar el an√°lisis de sentimientos\n",
        "df = df.withColumn(\"sentiment\", sentiment_udf(col(\"overview\")))\n",
        "\n",
        "# Convertir a Pandas para guardar los resultados si es necesario\n",
        "sentiment_results = df.select(\"title\", \"sentiment\").toPandas()\n",
        "\n",
        "# Guardar los resultados en un archivo .pkl\n",
        "joblib.dump(sentiment_results[\"sentiment\"].tolist(), \"sentiment_analysis_results.pkl\")\n",
        "\n",
        "# Mostrar algunos ejemplos\n",
        "df.select(\"title\", \"overview\", \"sentiment\").show(10, truncate=False)\n",
        "\n",
        "\n",
        "df = df.toPandas()\n",
        "\n",
        "df.to_csv('movies_.csv', index=False)"
      ],
      "metadata": {
        "id": "UQDe06CUsGDn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}