{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ru2lJ4XSUJ5_",
        "outputId": "f2aa27ce-99c3-4a47-9b5d-1ba1de5125a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rHit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "\u001b[33m\r0% [Connecting to archive.ubuntu.com (185.125.190.81)] [Connecting to security.\u001b[0m\r                                                                               \rHit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:3 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:4 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "53 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "\u001b[1;33mW: \u001b[0mSkipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\u001b[0m\n",
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.5.3)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.10/dist-packages (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "#Cargar\n",
        "\n",
        "!sudo apt update\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "#Check this site for the latest download link https://www.apache.org/dyn/closer.lua/spark/spark-3.2.1/spark-3.2.1-bin-hadoop3.2.tgz\n",
        "!wget -q https://archive.apache.org/dist/spark/spark-3.2.1/spark-3.2.1-bin-hadoop3.2.tgz\n",
        "!tar xf spark-3.2.1-bin-hadoop3.2.tgz\n",
        "!pip install -q findspark\n",
        "!pip install pyspark\n",
        "!pip install py4j\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear una sesión de Spark\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Movie_PIA\") \\\n",
        "    .getOrCreate()"
      ],
      "metadata": {
        "id": "Vr-JwYipUbhY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "outputId": "1f27a6d1-92fd-4829-a066-4751f47ee406"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ConnectionRefusedError",
          "evalue": "[Errno 111] Connection refused",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-455caf80a0e3>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mspark\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0mappName\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Movie_PIA\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;34m.\u001b[0m\u001b[0mgetOrCreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/sql/session.py\u001b[0m in \u001b[0;36mgetOrCreate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    491\u001b[0m                 \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_instantiatedSession\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msession\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m                     \u001b[0msparkConf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkConf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m                         \u001b[0msparkConf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/conf.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, loadDefaults, _jvm, _jconf)\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0m_jvm\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m                 \u001b[0;31m# JVM is created, so create self._jconf directly through JVM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jconf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparkConf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloadDefaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1710\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mUserHelpAutoCompletion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1712\u001b[0;31m         answer = self._gateway_client.send_command(\n\u001b[0m\u001b[1;32m   1713\u001b[0m             \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mREFLECTION_COMMAND_NAME\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1714\u001b[0m             \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mREFL_GET_UNKNOWN_SUB_COMMAND_NAME\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_id\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1034\u001b[0m          \u001b[0;32mif\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1035\u001b[0m         \"\"\"\n\u001b[0;32m-> 1036\u001b[0;31m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1037\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/py4j/clientserver.py\u001b[0m in \u001b[0;36m_get_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mconnection\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msocket\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m             \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_new_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/py4j/clientserver.py\u001b[0m in \u001b[0;36m_create_new_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    289\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_parameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython_parameters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m             self.gateway_property, self)\n\u001b[0;32m--> 291\u001b[0;31m         \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect_to_java_server\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    292\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_thread_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/py4j/clientserver.py\u001b[0m in \u001b[0;36mconnect_to_java_server\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    436\u001b[0m                 self.socket = self.ssl_context.wrap_socket(\n\u001b[1;32m    437\u001b[0m                     self.socket, server_hostname=self.java_address)\n\u001b[0;32m--> 438\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_address\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_port\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakefile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_connected\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mConnectionRefusedError\u001b[0m: [Errno 111] Connection refused"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TJ-UAuj0GBPk",
        "outputId": "638d7525-de36-4e95-8f46-2923969cbd9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# cargar el archivo limpio que ya está en mi drive\n",
        "\n",
        "file_path = '/content/drive/My Drive/movies_clean_final.csv'\n",
        "df = spark.read.csv(file_path, header=True, inferSchema=True)"
      ],
      "metadata": {
        "id": "sSeUZi5QGX4k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Revisar que columnas tienen nulos\n",
        "from pyspark.sql.functions import col, when, sum\n",
        "\n",
        "null_counts = df.select([sum(col(c).isNull().cast(\"int\")).alias(c) for c in df.columns])\n",
        "\n",
        "null_counts.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xUiw9We9Gz7U",
        "outputId": "a14dd90a-177e-4a86-d67e-d97e2a35b9df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+-----+------------+----------+------+------------+-------+-----+------+-----------------+--------------+--------+----------+------+--------------------+--------------------+----------------+------------+\n",
            "|movie_id|title|vote_average|vote_count|status|release_date|revenue|adult|budget|original_language|original_title|overview|popularity|genres|production_companies|production_countries|spoken_languages|year_release|\n",
            "+--------+-----+------------+----------+------+------------+-------+-----+------+-----------------+--------------+--------+----------+------+--------------------+--------------------+----------------+------------+\n",
            "|       0|    0|           0|         0|     0|           0|      0|    0|     0|                0|             0|     217|         5|     5|                   5|                   5|               5|           5|\n",
            "+--------+-----+------------+----------+------+------------+-------+-----+------+-----------------+--------------+--------+----------+------+--------------------+--------------------+----------------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Limpieza\n",
        "df = df.dropna()"
      ],
      "metadata": {
        "id": "mslEXeKdAJve"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l6SVJ-IX-I1J",
        "outputId": "bafc5f82-cc91-476a-ec01-9f5a6ddfef9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- movie_id: integer (nullable = true)\n",
            " |-- title: string (nullable = true)\n",
            " |-- vote_average: double (nullable = true)\n",
            " |-- vote_count: integer (nullable = true)\n",
            " |-- status: string (nullable = true)\n",
            " |-- release_date: string (nullable = true)\n",
            " |-- revenue: long (nullable = true)\n",
            " |-- adult: boolean (nullable = true)\n",
            " |-- budget: integer (nullable = true)\n",
            " |-- original_language: string (nullable = true)\n",
            " |-- original_title: string (nullable = true)\n",
            " |-- overview: string (nullable = true)\n",
            " |-- popularity: double (nullable = true)\n",
            " |-- genres: string (nullable = true)\n",
            " |-- production_companies: string (nullable = true)\n",
            " |-- production_countries: string (nullable = true)\n",
            " |-- spoken_languages: string (nullable = true)\n",
            " |-- year_release: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afTsTszF_cc6",
        "outputId": "1c4a9801-d39b-4ed2-fdd2-801900c99920"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+---------------+------------+----------+--------+------------+----------+-----+---------+-----------------+---------------+--------------------+----------+--------------------+--------------------+--------------------+--------------------+------------+\n",
            "|movie_id|          title|vote_average|vote_count|  status|release_date|   revenue|adult|   budget|original_language| original_title|            overview|popularity|              genres|production_companies|production_countries|    spoken_languages|year_release|\n",
            "+--------+---------------+------------+----------+--------+------------+----------+-----+---------+-----------------+---------------+--------------------+----------+--------------------+--------------------+--------------------+--------------------+------------+\n",
            "| 4520010|      Inception|       8.364|     34495|Released|   7/15/2010| 825532764|false|160000000|               en|      Inception|\\Cobb a skilled t...|    83.952|Action Science Fi...|Legendary Picture...|United Kingdom Un...|English French Ja...|        2010|\n",
            "| 4520011|   Interstellar|       8.417|     32571|Released|  11/05/2014| 701729206|false|165000000|               en|   Interstellar|The adventures of...|   140.241|Adventure Drama S...|Legendary Picture...|United Kingdom Un...|             English|        2014|\n",
            "| 4520012|The Dark Knight|       8.512|     30619|Released|   7/16/2008|1004558444|false|185000000|               en|The Dark Knight|Batman raises the...|   130.643|Drama Action Crim...|DC Comics Legenda...|United Kingdom Un...|    English Mandarin|        2008|\n",
            "| 4520013|         Avatar|       7.573|     29815|Released|  12/15/2009|2923706026|false|237000000|               en|         Avatar|In the 22nd centu...|    79.932|Action Adventure ...|Dune Entertainmen...|United States of ...|     English Spanish|        2009|\n",
            "| 4520014|   The Avengers|        7.71|     29166|Released|   4/25/2012|1518815515|false|220000000|               en|   The Avengers|When an unexpecte...|    98.082|Science Fiction A...|      Marvel Studios|United States of ...|English Hindi Rus...|        2012|\n",
            "+--------+---------------+------------+----------+--------+------------+----------+-----+---------+-----------------+---------------+--------------------+----------+--------------------+--------------------+--------------------+--------------------+------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pzUlMkAJ_caJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "N8I3QfyV_cXZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NurWo1jf_cUb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5bmFJbUz_cMS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xU4hQAta_beB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col, when\n",
        "\n",
        "#Crear una columna de \"mas votadas\" con valor de 1 y cero el resto\n",
        "df1 = df.withColumn(\"high_rating\", when(col(\"vote_average\") >= 7.0, 1).otherwise(0))\n",
        "\n",
        "#seleccionar columnas para el modelo\n",
        "features = [\"budget\", \"popularity\", \"revenue\", \"vote_count\", \"high_rating\"]\n",
        "\n",
        "#filtrar el df\n",
        "df1 = df1.select(features)\n",
        "\n",
        "#Quitar valores nulos\n",
        "df1 = df1.dropna()"
      ],
      "metadata": {
        "id": "DMIhwDuFWHYM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dividir el dataset entre conjunto de entrenamiento y prueba\n",
        "\n",
        "train_data1, test_data1 = df1.randomSplit([0.8, 0.2], seed=42)\n"
      ],
      "metadata": {
        "id": "dxB-aSMkXAd8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Regresión logística para estimar si una pelicula será \"altamente votada\" o no"
      ],
      "metadata": {
        "id": "I6pfngFGMykB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import LogisticRegression\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "\n",
        "# Crear el vector de características\n",
        "assembler = VectorAssembler(inputCols=['budget', 'popularity', 'revenue', 'vote_count'], outputCol='features')\n",
        "train_data1 = assembler.transform(train_data1)\n",
        "\n",
        "# Crear el modelo\n",
        "lr = LogisticRegression(featuresCol='features', labelCol='high_rating')\n",
        "\n",
        "# Entrenar el modelo\n",
        "model1 = lr.fit(train_data1)"
      ],
      "metadata": {
        "id": "6HTPJlMYXPAB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preparar los datos de prueba\n",
        "test_data1 = assembler.transform(test_data1)\n",
        "\n",
        "# Hacer predicciones\n",
        "predictions = model1.transform(test_data1)\n",
        "\n",
        "# Mostrar resultados\n",
        "predictions.select(\"high_rating\", \"prediction\").show(10)\n",
        "\n",
        "# Evaluación\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "\n",
        "evaluator = BinaryClassificationEvaluator(labelCol=\"high_rating\", rawPredictionCol=\"prediction\")\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "print(f\"Precisión del modelo: {accuracy:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LoRF8RxKXssZ",
        "outputId": "8b87eac8-eaff-491a-e364-0ff85dc6b007"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+----------+\n",
            "|high_rating|prediction|\n",
            "+-----------+----------+\n",
            "|          1|       0.0|\n",
            "|          1|       0.0|\n",
            "|          0|       0.0|\n",
            "|          0|       0.0|\n",
            "|          0|       0.0|\n",
            "|          0|       0.0|\n",
            "|          0|       0.0|\n",
            "|          0|       0.0|\n",
            "|          0|       0.0|\n",
            "|          0|       0.0|\n",
            "+-----------+----------+\n",
            "only showing top 10 rows\n",
            "\n",
            "Precisión del modelo: 0.51\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model1.save(\"logistic_regression_model\")"
      ],
      "metadata": {
        "id": "lUOcxprpYUp5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "import numpy as np\n",
        "\n",
        "# Extraer los coeficientes y el intercepto\n",
        "coef = np.array(model1.coefficients)\n",
        "intercept = np.array(model1.intercept)\n",
        "\n",
        "# Guardar coeficientes y el intercepto utilizando joblib\n",
        "joblib.dump((coef, intercept), \"logistic_regression_coefficients.pkl\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OMUnDDgIYfw4",
        "outputId": "d24cba5a-8063-4240-e334-da427fd7b835"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['logistic_regression_coefficients.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Segundo modelo\n",
        "\n"
      ],
      "metadata": {
        "id": "e3ILXP3jNRn7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql import functions as F\n",
        "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
        "from pyspark.ml import Pipeline"
      ],
      "metadata": {
        "id": "IY9CENFRTFEY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = df.select(\"movie_id\", \"title\", \"budget\", \"popularity\", \"revenue\", \"vote_average\", \"vote_count\")\n",
        "# Seleccionar y procesar columnas numéricas\n",
        "numeric_columns = [\"vote_average\", \"vote_count\", \"revenue\", \"budget\", \"popularity\"]\n",
        "\n",
        "# Crear un vector de características y escalarlo\n",
        "assembler = VectorAssembler(inputCols=numeric_columns, outputCol=\"features\")\n",
        "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaled_features\")\n",
        "\n",
        "# Pipeline para preprocesamiento\n",
        "pipeline = Pipeline(stages=[assembler, scaler])\n",
        "df_preprocessed = pipeline.fit(df2).transform(df2)\n",
        "\n",
        "# Mostrar datos preprocesados\n",
        "df_preprocessed.select(\"movie_id\", \"title\", \"scaled_features\").show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4g_cjHcXTYJR",
        "outputId": "70f609c0-dd06-48d6-bacf-759c9e1edf8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+-------------------------------------------------+-----------------------------------------------------------------------------------------------+\n",
            "|movie_id|title                                            |scaled_features                                                                                |\n",
            "+--------+-------------------------------------------------+-----------------------------------------------------------------------------------------------+\n",
            "|4520010 |Inception                                        |[2.6631819085474744,52.521391172026746,24.82587604873595,17.543447948063786,5.532013478671557] |\n",
            "|4520011 |Interstellar                                     |[2.6800576427838463,49.59194758266656,21.10278725162009,18.09168069644078,9.241174745835453]   |\n",
            "|4520012 |The Dark Knight                                  |[2.7103066003773435,46.619871758118194,30.20963491941436,20.284611689948754,8.608714942992284] |\n",
            "|4520013 |Avatar                                           |[2.4113195353216192,45.39571757628577,87.92329822589375,25.986232273069483,5.267115749204009]  |\n",
            "|4520014 |The Avengers                                     |[2.4549417162722413,44.407563267816556,45.67465685261046,24.122240928587708,6.4631092292627175]|\n",
            "|4520015 |Deadpool                                         |[2.4218270679593603,43.993421554559816,23.549814594354636,6.3594998811731225,4.792869739508001]|\n",
            "|4520016 |Avengers: Infinity War                           |[2.6284752098349355,42.195254777514926,61.72135568779867,32.8939649026196,10.170227752741663]  |\n",
            "|4520017 |Fight Club                                       |[2.686744254462409,41.472029359143775,3.0329296185606407,6.907732629550116,4.579567761824803]  |\n",
            "|4520018 |Guardians of the Galaxy                          |[2.5173500919388245,40.55848146225391,23.239363622597057,18.639913444817772,2.191336814289387] |\n",
            "|4520019 |Pulp Fiction                                     |[2.7026647584589862,39.42415949028232,6.432518633293904,0.9319956722408886,4.933028314278517]  |\n",
            "|4520020 |Forrest Gump                                     |[2.699162247579739,38.68723085345783,20.370776555093034,6.030560232146927,6.108001302869528]   |\n",
            "|4520021 |Harry Potter and the Philosophers Stone          |[2.52053419273814,38.64155345861333,29.365110660733585,13.705818709424834,12.22232852166664]   |\n",
            "|4520022 |Iron Man                                         |[2.4326530106770328,37.87265064539769,17.59768156492877,15.350516954555813,4.803544722635798]  |\n",
            "|4520023 |Django Unchained                                 |[2.601728763120685,37.565089520111435,12.791907980114054,10.964654967539866,3.573088179763275] |\n",
            "|4520024 |The Shawshank Redemption                         |[2.7708045155643375,37.53007018406399,0.852300268524645,2.7411637418849666,8.07938074876024]   |\n",
            "|4520025 |Avengers: Endgame                                |[2.6310224904743875,36.324186960169364,84.20314246481034,39.03417168444193,6.046257727618013]  |\n",
            "|4520026 |The Matrix                                       |[2.612873115918289,36.26023860738707,13.939150084166092,6.907732629550116,5.176971447235946]   |\n",
            "|4520027 |Titanic                                          |[2.5154396314592358,35.989219397976406,68.0891375618283,21.929309935079733,6.744217118294698]  |\n",
            "|4520028 |Joker                                            |[2.6007735328808903,35.66643247440866,32.311701354193346,6.030560232146927,3.592724877121815]  |\n",
            "|4520029 |The Lord of the Rings: The Fellowship of the Ring|[2.675281491584873,35.511129331937376,26.20426946186454,10.197129119812077,5.735299422802749]  |\n",
            "+--------+-------------------------------------------------+-----------------------------------------------------------------------------------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.linalg import DenseVector\n",
        "\n",
        "def compare_movies(movie_id_1, movie_id_2):\n",
        "    # Seleccionar las películas\n",
        "    movie_1 = df_preprocessed.filter(F.col(\"movie_id\") == movie_id_1).select(\"title\", \"scaled_features\").first()\n",
        "    movie_2 = df_preprocessed.filter(F.col(\"movie_id\") == movie_id_2).select(\"title\", \"scaled_features\").first()\n",
        "\n",
        "    if not movie_1 or not movie_2:\n",
        "        raise ValueError(\"Uno o ambos movie_id no existen en el conjunto de datos.\")\n",
        "\n",
        "    # Extraer atributos escalados\n",
        "    title_1, features_1 = movie_1[\"title\"], movie_1[\"scaled_features\"]\n",
        "    title_2, features_2 = movie_2[\"title\"], movie_2[\"scaled_features\"]\n",
        "\n",
        "    # Calcular las diferencias entre los atributos\n",
        "    differences = [abs(f1 - f2) for f1, f2 in zip(features_1, features_2)]\n",
        "    comparison = {\n",
        "        \"movie_1\": title_1,\n",
        "        \"movie_2\": title_2,\n",
        "        \"differences\": differences,\n",
        "        \"attributes\": numeric_columns\n",
        "    }\n",
        "    return comparison\n",
        "\n",
        "# Ejemplo de comparación\n",
        "comparison_result = compare_movies(4520010, 4520011)\n",
        "print(comparison_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pHj0AVwjT68A",
        "outputId": "66529bf3-4c4b-43f2-902a-2d01cd596f91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'movie_1': 'Inception', 'movie_2': 'Interstellar', 'differences': [0.016875734236371898, 2.929443589360183, 3.72308879711586, 0.5482327483769929, 3.7091612671638963], 'attributes': ['vote_average', 'vote_count', 'revenue', 'budget', 'popularity']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "from typing import Dict\n",
        "\n",
        "class MovieComparisonModel:\n",
        "    def __init__(self, df_preprocessed, numeric_columns):\n",
        "        \"\"\"\n",
        "        Inicializa el modelo de comparación de películas.\n",
        "\n",
        "        Args:\n",
        "            df_preprocessed: DataFrame de PySpark preprocesado con columnas escaladas.\n",
        "            numeric_columns: Lista de nombres de columnas numéricas para la comparación.\n",
        "        \"\"\"\n",
        "        self.df_preprocessed = df_preprocessed\n",
        "        self.numeric_columns = numeric_columns\n",
        "\n",
        "    def find_movie_by_title(self, title: str) -> Dict:\n",
        "        \"\"\"\n",
        "        Busca una película por su título.\n",
        "\n",
        "        Args:\n",
        "            title: Título de la película.\n",
        "\n",
        "        Returns:\n",
        "            Diccionario con el ID y los atributos de la película.\n",
        "        \"\"\"\n",
        "        movie = self.df_preprocessed.filter(F.col(\"title\") == title).first()\n",
        "        if not movie:\n",
        "            raise ValueError(f\"Película con título '{title}' no encontrada.\")\n",
        "        return {\"movie_id\": movie[\"movie_id\"], \"title\": movie[\"title\"], \"scaled_features\": movie[\"scaled_features\"]}\n",
        "\n",
        "    def compare_movies_by_title(self, title_1: str, title_2: str) -> Dict:\n",
        "        \"\"\"\n",
        "        Compara dos películas por su título.\n",
        "\n",
        "        Args:\n",
        "            title_1: Título de la primera película.\n",
        "            title_2: Título de la segunda película.\n",
        "\n",
        "        Returns:\n",
        "            Diccionario con la comparación de atributos.\n",
        "        \"\"\"\n",
        "        movie_1 = self.find_movie_by_title(title_1)\n",
        "        movie_2 = self.find_movie_by_title(title_2)\n",
        "\n",
        "        differences = [\n",
        "            abs(f1 - f2) for f1, f2 in zip(movie_1[\"scaled_features\"], movie_2[\"scaled_features\"])\n",
        "        ]\n",
        "\n",
        "        return {\n",
        "            \"movie_1\": movie_1[\"title\"],\n",
        "            \"movie_2\": movie_2[\"title\"],\n",
        "            \"differences\": differences,\n",
        "            \"attributes\": self.numeric_columns,\n",
        "        }"
      ],
      "metadata": {
        "id": "Bw7BKOmWUF2g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "import numpy as np\n",
        "from pyspark.sql import functions as F\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.sql import SparkSession\n",
        "import pickle\n",
        "\n",
        "df2 = df.select(\"movie_id\", \"title\", \"budget\", \"popularity\", \"revenue\", \"vote_average\", \"vote_count\")\n",
        "\n",
        "# Selección de columnas para el modelo\n",
        "numeric_columns = [\"budget\", \"revenue\", \"vote_average\", \"vote_count\", \"popularity\"]\n",
        "\n",
        "# Usar VectorAssembler para combinar las columnas numéricas en un solo vector\n",
        "assembler = VectorAssembler(inputCols=numeric_columns, outputCol=\"features\")\n",
        "df2 = assembler.transform(df2)\n",
        "\n",
        "# Escalar los valores de las características usando MinMaxScaler (opcional pero útil para la comparación)\n",
        "from pyspark.ml.feature import MinMaxScaler\n",
        "scaler = MinMaxScaler(inputCol=\"features\", outputCol=\"scaled_features\")\n",
        "scaler_model = scaler.fit(df2)\n",
        "df_scaled = scaler_model.transform(df2)\n",
        "\n",
        "# Extraer los coeficientes (características escaladas) para compararlas\n",
        "df_scaled = df_scaled.select(\"movie_id\", \"title\", \"scaled_features\")\n",
        "movies = df_scaled.collect()\n",
        "\n",
        "# Crear un diccionario con los coeficientes\n",
        "coef_dict = {}\n",
        "for movie in movies:\n",
        "    coef_dict[movie[\"title\"]] = np.array(movie[\"scaled_features\"])\n",
        "\n",
        "# Guardar los coeficientes en un archivo .pkl\n",
        "with open(\"movie_comparison_coefficients.pkl\", \"wb\") as f:\n",
        "    joblib.dump(coef_dict, f)\n",
        "\n",
        "print(\"Modelo guardado como 'movie_comparison_coefficients.pkl'.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HlVQHfi_W0lY",
        "outputId": "8318ecad-ad5f-4dd1-95fc-c5840292e9fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modelo guardado como 'movie_comparison_coefficients.pkl'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col, max\n",
        "\n",
        "\n",
        "df3 = df\n",
        "\n",
        "df3.show(5)\n",
        "df3.printSchema()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tg0TvtFP1Tfc",
        "outputId": "e9bda37a-0ae6-4741-af97-47fd65702c92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+---------------+------------+----------+--------+------------+----------+-----+---------+-----------------+---------------+--------------------+----------+--------------------+--------------------+--------------------+--------------------+------------+\n",
            "|movie_id|          title|vote_average|vote_count|  status|release_date|   revenue|adult|   budget|original_language| original_title|            overview|popularity|              genres|production_companies|production_countries|    spoken_languages|year_release|\n",
            "+--------+---------------+------------+----------+--------+------------+----------+-----+---------+-----------------+---------------+--------------------+----------+--------------------+--------------------+--------------------+--------------------+------------+\n",
            "| 4520010|      Inception|       8.364|     34495|Released|   7/15/2010| 825532764|false|160000000|               en|      Inception|\\Cobb a skilled t...|    83.952|Action Science Fi...|Legendary Picture...|United Kingdom Un...|English French Ja...|        2010|\n",
            "| 4520011|   Interstellar|       8.417|     32571|Released|  11/05/2014| 701729206|false|165000000|               en|   Interstellar|The adventures of...|   140.241|Adventure Drama S...|Legendary Picture...|United Kingdom Un...|             English|        2014|\n",
            "| 4520012|The Dark Knight|       8.512|     30619|Released|   7/16/2008|1004558444|false|185000000|               en|The Dark Knight|Batman raises the...|   130.643|Drama Action Crim...|DC Comics Legenda...|United Kingdom Un...|    English Mandarin|        2008|\n",
            "| 4520013|         Avatar|       7.573|     29815|Released|  12/15/2009|2923706026|false|237000000|               en|         Avatar|In the 22nd centu...|    79.932|Action Adventure ...|Dune Entertainmen...|United States of ...|     English Spanish|        2009|\n",
            "| 4520014|   The Avengers|        7.71|     29166|Released|   4/25/2012|1518815515|false|220000000|               en|   The Avengers|When an unexpecte...|    98.082|Science Fiction A...|      Marvel Studios|United States of ...|English Hindi Rus...|        2012|\n",
            "+--------+---------------+------------+----------+--------+------------+----------+-----+---------+-----------------+---------------+--------------------+----------+--------------------+--------------------+--------------------+--------------------+------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "root\n",
            " |-- movie_id: integer (nullable = true)\n",
            " |-- title: string (nullable = true)\n",
            " |-- vote_average: double (nullable = true)\n",
            " |-- vote_count: integer (nullable = true)\n",
            " |-- status: string (nullable = true)\n",
            " |-- release_date: string (nullable = true)\n",
            " |-- revenue: long (nullable = true)\n",
            " |-- adult: boolean (nullable = true)\n",
            " |-- budget: integer (nullable = true)\n",
            " |-- original_language: string (nullable = true)\n",
            " |-- original_title: string (nullable = true)\n",
            " |-- overview: string (nullable = true)\n",
            " |-- popularity: double (nullable = true)\n",
            " |-- genres: string (nullable = true)\n",
            " |-- production_companies: string (nullable = true)\n",
            " |-- production_countries: string (nullable = true)\n",
            " |-- spoken_languages: string (nullable = true)\n",
            " |-- year_release: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Paso 1: Obtener la película con mayor budget por año\n",
        "max_budget = df3.groupBy(\"year_release\").agg(max(\"budget\").alias(\"max_budget\"))\n",
        "merged_budget = df3.join(max_budget, (df3.year_release == max_budget.year_release) & (df3.budget == max_budget.max_budget), \"inner\") \\\n",
        "                   .select(df3[\"*\"], max_budget[\"max_budget\"])  # Selecciona columnas de df y max_budget\n",
        "\n",
        "# Paso 2: Obtener la película con mayor revenue por año\n",
        "max_revenue = df3.groupBy(\"year_release\").agg(max(\"revenue\").alias(\"max_revenue\"))\n",
        "merged_revenue = merged_budget.join(max_revenue, (merged_budget.year_release == max_revenue.year_release) & (merged_budget.revenue == max_revenue.max_revenue), \"inner\") \\\n",
        "                               .select(merged_budget[\"*\"], max_revenue[\"max_revenue\"])  # Selecciona columnas de merged_budget y max_revenue\n",
        "\n",
        "# Paso 3: Obtener la película con mayor vote_average por año\n",
        "max_vote_average = df3.groupBy(\"year_release\").agg(max(\"vote_average\").alias(\"max_vote_average\"))\n",
        "final_result = merged_revenue.join(max_vote_average, (merged_revenue.year_release == max_vote_average.year_release) & (merged_revenue.vote_average == max_vote_average.max_vote_average), \"inner\") \\\n",
        "                              .select(merged_revenue[\"*\"], max_vote_average[\"max_vote_average\"])  # Selecciona columnas de merged_revenue y max_vote_average\n",
        "\n",
        "# Seleccionar solo las columnas necesarias para el resultado final\n",
        "final_output = final_result.select(\n",
        "    \"year_release\",\n",
        "    \"title\",\n",
        "    \"budget\",\n",
        "    \"revenue\",\n",
        "    \"vote_average\"\n",
        ")"
      ],
      "metadata": {
        "id": "_AKbKMctmmqG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import HashingTF, IDF\n",
        "from pyspark.ml.linalg import DenseVector\n",
        "from pyspark.sql.functions import col, udf\n",
        "from transformers import pipeline\n",
        "from pyspark.sql.functions import udf, col\n",
        "from pyspark.sql.types import StringType\n",
        "from textblob import TextBlob\n",
        "\n",
        "# Crear una sesión de Spark\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Movie_PIA\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# cargar el archivo limpio que ya está en mi drive\n",
        "\n",
        "file_path = '/content/drive/My Drive/movies_clean_final.csv'\n",
        "df = spark.read.csv(file_path, header=True, inferSchema=True)\n",
        "\n",
        "# Definir una función para calcular el sentimiento\n",
        "def analyze_sentiment(text):\n",
        "    if text is None or text.strip() == \"\":\n",
        "        return \"Neutral\"\n",
        "    polarity = TextBlob(text).sentiment.polarity\n",
        "    if polarity > 0:\n",
        "        return \"Positivo\"\n",
        "    elif polarity < 0:\n",
        "        return \"Negativo\"\n",
        "    else:\n",
        "        return \"Neutral\"\n",
        "\n",
        "# Registrar la función como UDF\n",
        "sentiment_udf = udf(analyze_sentiment, StringType())\n",
        "\n",
        "# Aplicar el análisis de sentimientos\n",
        "df = df.withColumn(\"sentiment\", sentiment_udf(col(\"overview\")))\n",
        "\n",
        "# Convertir a Pandas para guardar los resultados si es necesario\n",
        "sentiment_results = df.select(\"title\", \"sentiment\").toPandas()\n",
        "\n",
        "# Guardar los resultados en un archivo .pkl\n",
        "joblib.dump(sentiment_results[\"sentiment\"].tolist(), \"sentiment_analysis_results.pkl\")\n",
        "\n",
        "# Mostrar algunos ejemplos\n",
        "df.select(\"title\", \"overview\", \"sentiment\").show(10, truncate=False)\n",
        "\n",
        "\n",
        "df = df.toPandas()\n",
        "\n",
        "df.to_csv('movies_.csv', index=False)"
      ],
      "metadata": {
        "id": "UQDe06CUsGDn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}